{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import win32api\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks available drives. important that G: drive appears here.\n",
    "drives = win32api.GetLogicalDriveStrings()\n",
    "drives = drives.split('\\000')[:-1]\n",
    "print (drives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare full path where the files are saved\n",
    "cwd = os.path.abspath('G:\\\\ALL\\RETAIL TRADING PODS\\SOUTH\\Planning\\FW21\\sales_launch\\sl_feedback') \n",
    "#declare sheet name. template must have data as the name of the sheet\n",
    "my_sheet = \"SUMMARY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks files inside the folder\n",
    "files = os.listdir(cwd) \n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize empty df\n",
    "df = pd.DataFrame()\n",
    "#initialize empty list to append resutls from below loop.\n",
    "appended_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>>>>>>>>>>>>>>>>>>>>>>>>>>>below loop will run 1-by-1 on all files saved in folder<<<<<<<<<<<<<<<<<<<\n",
    "for file in files:\n",
    "    \n",
    "    #define name of the file >> import to current df\n",
    "    full_file = cwd + \"\\\\\" + file\n",
    "    df = pd.read_excel(full_file, sheet_name=my_sheet, ignore_index=True)\n",
    "    \n",
    "    #>>>>>>>>>>>>Next section cleans data (unwanted rows and columns)\n",
    "    #drop all columns from sections we dont care about (eg. d, e,f, etc.)\n",
    "    #df=df.drop(df.filter(like='d',axis=1).columns,axis=1)\n",
    "    #df=df.drop(df.filter(like='e',axis=1).columns,axis=1)\n",
    "    #df=df.drop(df.filter(like='f',axis=1).columns,axis=1)\n",
    "    #df=df.drop(df.filter(like='g',axis=1).columns,axis=1)\n",
    "    #df=df.drop(df.filter(like='h',axis=1).columns,axis=1)\n",
    "    #df=df.drop(df.filter(like='x',axis=1).columns,axis=1)\n",
    "     \n",
    "    #renames first column called 'a' to pc9.\n",
    "    #df.rename(columns={'a': 'pc9'}, inplace=True)\n",
    "    #other columns a1, a2, etc. had been created. this deletes all those unwanted columns\n",
    "    #df = df[df.columns.drop(list(df.filter(regex='a')))]\n",
    "    #this deletes of all rows where pc9 is NA.\n",
    "    df = df[df[5].notna()]\n",
    "    \n",
    "    #at this stage, the df has generic column names, eg. 0, 1, 2, etc.\n",
    "    #Below renames columns of dataframe to first row (which contains titles in the excel)\n",
    "    #df.columns = df.iloc[1]\n",
    "    #This gets rid of first row (ie. title rows from excel), so only data remains in df\n",
    "    #df = df[2:]\n",
    "    #renames column material to pc9. just to make code easier.\n",
    "    #df.rename(columns={'Material code': 'pc9'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    #>>>>>>>>>>>>>>this 1 line of magic unpivots the data :). amazing.\n",
    "    #df = df.melt(id_vars=['pc9'],var_name='key', value_name='selected')\n",
    "    \n",
    "    \n",
    "    #>>>>> Next section creates mini dataframe 'new', to split key into separate columns (shipto and measure)\n",
    "    # new data frame with split value columns \n",
    "    #new = df[\"key\"].str.split(\"|\", n = 1, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    #df[\"ship_to\"]= new[0] \n",
    "    # making separate last name column from new data frame \n",
    "    #df[\"measure\"]= new[1] \n",
    "    ##Add file name to df\n",
    "    df[\"source_file\"] = file\n",
    "    # Dropping old Name columns \n",
    "    #df.drop(columns =[\"key\"], inplace = True) \n",
    "    \n",
    "    #>>>>>>>> next section appends current df into the list. it will stack one file after another.\n",
    "    appended_data.append(df)\n",
    "    \n",
    "    #>>>>>>>End of loop. It will repeat for every file in our folder.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>>>>>>> this converts list into a data frame with the same name. list ceases to exist.\n",
    "appended_data = pd.concat(appended_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_name = \"sl_summary_\"+timestr+\".xlsx\"\n",
    "print (file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data.to_excel(file_name) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
