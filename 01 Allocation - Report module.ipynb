{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiles for Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Christian C. Feb/2020 (With majority of code being reused from Stack exchange and Google)\n",
    "\n",
    "-Functionality: This module puts together csv created in previous module. And creates final report\n",
    "(cleans data, aligns naming, creates templates, and puts all info together in final data frame/report).\n",
    "\n",
    "-Note: Kept it for the moment in 2 separate modules for readability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\CAS233\\\\Notebooks Christian\\\\DS_importing wave2\\\\Dataframes\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basepath = path\n",
    "#for entry in os.listdir(basepath):\n",
    "#    if os.path.isfile(os.path.join(basepath, entry)):\n",
    "#        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_ds4.shape)\n",
    "#print(df_ds4['ND QTY'].sum())\n",
    "#print(5682547+7252989+794987)\n",
    "#print(\"*********\")\n",
    "#print(df_ds1.shape)\n",
    "#print(df_ds1['ND QTY'].sum())\n",
    "#print(21385565+3243461)\n",
    "#print(\"*********\")\n",
    "#print(df_SGMT.shape)\n",
    "#print(df_conso.shape)\n",
    "#print(df_waterfall.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports CSV base files into separate dataframes (1 df per csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "input_files = ['df_ds1', 'df_ds4','df_SGMT', 'df_waterfall','df_conso']\n",
    "\n",
    "for my_file in input_files:\n",
    " \n",
    "    df = pd.read_csv(my_file+\".csv\")\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "  \n",
    "    exec(str(my_file)+\" = df\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_MFP.csv', converters={'PC5': lambda x: str(x)})\n",
    "df_MFP = df\n",
    "\n",
    "df = pd.read_csv('df_PG.csv')\n",
    "df_pg = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filters Months. IT sends now downloads for full horizon so filter as you wish here\n",
    "my_months_list =['2020.06', '2020.07', '2020.08', '2020.09', '2020.10', '2020.11', '2020.12', '2021.01']\n",
    "df_ds1 = df_ds1[df_ds1.FISCAL.isin(my_months_list)]\n",
    "df_ds4 = df_ds4[df_ds4.FISCAL.isin(my_months_list)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align field naming convention between dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conso.rename({'Colorway Code': 'PC9', 'Product Code': 'PC5'}, axis='columns',inplace=True)\n",
    "df_SGMT.rename({'Planning Group': 'PG'}, axis='columns',inplace=True)\n",
    "df_waterfall.rename({'Account': 'PG', 'Material': 'PC9', 'SumOfQtyTotal': 'QTY_WF'}, axis='columns',inplace=True)\n",
    "df_ds4.rename({'PG DESC': 'PG'},axis='columns',inplace=True)\n",
    "\n",
    "#Drops unneeded columns from df waterfall. For cleaner code this could happen on previous module.\n",
    "df_waterfall.drop(columns=['SalesOffice','Channel','Add/Drop'], axis=1,inplace=True)\n",
    "\n",
    "#Gets rid of spaces in sizes. For cleaner code this could happen on previous module.\n",
    "df_SGMT.W = df_SGMT.W.str.strip()\n",
    "df_SGMT.L = df_SGMT.L.str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['LSE OUTLET UK', 'LSE OUTLET EU', 'TURKEY OUTLET']\n",
      "['LSE OUTLET UK', 'LSE OUTLET EU', 'TURKEY OUTLET']\n"
     ]
    }
   ],
   "source": [
    "list_0 = df_pg['PG'].unique()\n",
    "list_1 = df_waterfall['PG'].unique()\n",
    "list_2 = df_SGMT['PG'].unique()\n",
    "list_3 = df_ds4['PG'].unique()\n",
    "print(list(set(list_0).difference(list_1)))\n",
    "print(list(set(list_0).difference(list_2)))\n",
    "print(list(set(list_0).difference(list_3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates Dataframe \"df_basis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df_basis. Conso is the start of it. SGMT next. MFP next. PG next.\n",
    "df_basis = pd.merge(df_conso,df_SGMT, on='PC9', how='left')\n",
    "df_basis = pd.merge(df_basis,df_waterfall, on=['PC9','PG'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_MFP, on=['PC5'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_pg, on=['PG'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepares DS1 and DS4 dataframes for creation of Profile Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds MPF to DS1\n",
    "df_ds1[\"PC5\"] = df_ds1[\"PC9\"].str[:5]\n",
    "df_ds1 = pd.merge(df_ds1,df_MFP, on=['PC5'], how='left')\n",
    "\n",
    "#adds MFP to DS4\n",
    "df_ds4[\"PC5\"] = df_ds4[\"PC9\"].str[:5]\n",
    "df_ds4 = pd.merge(df_ds4,df_MFP, on=['PC5'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds W and L to DS1\n",
    "new = df_ds1[\"SZ\"].str.split(\" +\", n = 1, expand = True)\n",
    "new.rename(columns={0: \"W\", 1: \"L\"}, inplace=True)\n",
    "new.L.fillna(value=pd.np.nan, inplace=True)\n",
    "new['L'].fillna('-', inplace=True)\n",
    "df_ds1[\"W\"]= new['W'] \n",
    "df_ds1[\"L\"]= new['L'] \n",
    "\n",
    "#adds W and L to DS4\n",
    "new = df_ds4[\"SZ\"].str.split(\" +\", n = 1, expand = True)\n",
    "new.rename(columns={0: \"W\", 1: \"L\"}, inplace=True)\n",
    "new.L.fillna(value=pd.np.nan, inplace=True)\n",
    "new['L'].fillna('-', inplace=True)\n",
    "df_ds4[\"W\"]= new['W'] \n",
    "df_ds4[\"L\"]= new['L'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates Profile Templates (ie. profiles by pc9, pc5, MFP; from DS1 and DS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds1 pg pc9\n",
    "df_a = df_ds1.groupby(['CHANNEL','AFFILIATE','PC9','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds1.groupby(['CHANNEL','AFFILIATE','PC9'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['PC9','CHANNEL','AFFILIATE'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds1_pc9'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds1_pc9 = df\n",
    "\n",
    "#ds4 pg pc9\n",
    "df_a = df_ds4.groupby(['PG','PC9','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds4.groupby(['PG','PC9'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['PC9','PG'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds4_pc9'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds4_pc9 = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds1 ch/aff pc5\n",
    "df_a = df_ds1.groupby(['CHANNEL','AFFILIATE','PC5','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds1.groupby(['CHANNEL','AFFILIATE','PC5'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['PC5','CHANNEL','AFFILIATE'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds1_pc5'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds1_pc5 = df\n",
    "\n",
    "#ds4 pg pc5\n",
    "df_a = df_ds4.groupby(['PG','PC5','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds4.groupby(['PG','PC5'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['PC5','PG'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds4_pc5'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds4_pc5 = df\n",
    "\n",
    "#ds1 ch/aff mfp\n",
    "df_a = df_ds1.groupby(['CHANNEL','AFFILIATE','MFP','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds1.groupby(['CHANNEL','AFFILIATE','MFP'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['MFP','CHANNEL','AFFILIATE'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds1_mfp'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds1_mfp = df\n",
    "\n",
    "#ds4 ch/aff mfp\n",
    "df_a = df_ds4.groupby(['PG','MFP','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds4.groupby(['PG','MFP'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['MFP','PG'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds4_mfp'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds4_mfp = df\n",
    "\n",
    "\n",
    "#ds1 lse pc5\n",
    "df_a = df_ds1.groupby(['PC5','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds1.groupby(['PC5'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['PC5'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds1_pc5_lse'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds1_pc5_lse = df\n",
    "\n",
    "\n",
    "#ds1 lse mfp\n",
    "df_a = df_ds1.groupby(['MFP','W','L'], as_index=False)['ND QTY'].sum()\n",
    "df_b = df_ds1.groupby(['MFP'], as_index=False)['ND QTY'].sum()\n",
    "\n",
    "df = pd.merge(df_a, df_b, on=['MFP'], how='left')\n",
    "df['ND QTY_x'] = df['ND QTY_x'].astype(float) \n",
    "df['ND QTY_y'] = df['ND QTY_y'].astype(float) \n",
    "df['df_ds1_mfp_lse'] = df['ND QTY_x']/df['ND QTY_y']\n",
    "\n",
    "df_ds1_mfp_lse = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appends templates to \"basis_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basis = pd.merge(df_basis,df_ds1_pc9, on=['PC9','W','L','CHANNEL','AFFILIATE'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_ds4_pc9, on=['PC9','W','L','PG'], how='left')\n",
    "\n",
    "df_basis = pd.merge(df_basis,df_ds1_pc5, on=['PC5','W','L','CHANNEL','AFFILIATE'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_ds4_pc5, on=['PC5','W','L','PG'], how='left')\n",
    "\n",
    "df_basis = pd.merge(df_basis,df_ds1_mfp, on=['MFP','W','L','CHANNEL','AFFILIATE'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_ds4_mfp, on=['MFP','W','L','PG'], how='left')\n",
    "\n",
    "df_basis = pd.merge(df_basis,df_ds1_pc5_lse, on=['PC5','W','L'], how='left')\n",
    "df_basis = pd.merge(df_basis,df_ds1_mfp_lse, on=['MFP','W','L'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning to \"basis_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Nan and remove unnecessary columns created during merges\n",
    "df_basis = df_basis.fillna(0)\n",
    "df_basis = df_basis.drop(['ND QTY_x_x','ND QTY_x_y', 'ND QTY_y_x', 'ND QTY_y_y'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort order of columns (only for personal preference)\n",
    "df_basis = df_basis[['CHANNEL','AFFILIATE', 'PG',\n",
    "                     'PC9', 'PC5', 'QTY_WF',\n",
    "                    'Add/Drop','Department','Mainline/OPP/Concepts','LSE Merch Story', 'MFP categorization','MFP',\n",
    "                    'Product Name','New or C/O or D0','Sizes','Size Grid Name',\n",
    "                    'Size','Selected','W','L',\n",
    "                      'df_ds4_pc9','df_ds4_pc5','df_ds4_mfp',\n",
    "                      'df_ds1_pc9','df_ds1_pc5','df_ds1_mfp',\n",
    "                      'df_ds1_pc5_lse','df_ds1_mfp_lse'\n",
    "                     ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter rows\n",
    "#I only want to see records with Forecast > 0 from waterfall, that are not dropped in conso, \n",
    "#and only the PGs selected below.\n",
    "filter_1 = df_basis['QTY_WF'] > 0\n",
    "filter_2 = df_basis['Add/Drop'] != \"DROP\"\n",
    "filter_list_3 = ['NORDICS RETAIL','EE RETAIL','FRANCE RETAIL','CENTRAL RETAIL',\n",
    "                'ITALY RETAIL', 'ITALY KEY ACCOUNTS',\n",
    "                 'RUSSIA RETAIL',\n",
    "                 'SPAIN RETAIL', 'EL CORTE INGLES CONCESSION',\n",
    "                 'TURKEY RETAIL','BOYNER TURKEY CONCESSION',\n",
    "                 'NORTH RETAIL',\n",
    "                 'ECOM EU','ECOM UK',\n",
    "                'GALERIES LAFAYETTE','PRINTEMPS']\n",
    "\n",
    "#Copies a subsett of df_basis, and assigns it to new dataframe df_basis2\n",
    "#i kept a copy for easier debugging from my side.\n",
    "df_basis2 = df_basis[(filter_1) & (filter_2)]\n",
    "df_basis2 = df_basis2[df_basis2.PG.isin(filter_list_3)]\n",
    "df_basis2 = df_basis2.sort_values(by=['CHANNEL', 'AFFILIATE','PG','PC9','W','L'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates new fields in df_basis 2, to keep track final profile, from which template is it grabbing it,\n",
    "#and flagging at the end of the exercise if a profile is still missing.\n",
    "df_basis2['PROFILE'] = 0.00\n",
    "df_basis2['LVL'] = 0\n",
    "df_basis2['STILL_MISSING'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\CAS233\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Populates column with Final profile (the column that the final users at Allocation team will look at).\n",
    "#and puts a flag from 1 to 8, to know later from which template it grabbed the profile from.\n",
    "\n",
    "#set initial value\n",
    "df_basis2['PROFILE'] = df_basis2['df_ds4_pc9']\n",
    "df_basis2['LVL'] = 1\n",
    "\n",
    "#Start filling blanks\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds4_pc5']\n",
    "df_basis2['LVL'][mask] = 2\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds4_mfp']\n",
    "df_basis2['LVL'][mask] = 3\n",
    "\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds1_pc9']\n",
    "df_basis2['LVL'][mask] = 4\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds1_pc5']\n",
    "df_basis2['LVL'][mask] = 5\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds1_mfp']\n",
    "df_basis2['LVL'][mask] = 6\n",
    "\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds1_pc5_lse']\n",
    "df_basis2['LVL'][mask] = 7\n",
    "\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['PROFILE'][mask] = df_basis2['df_ds1_mfp_lse']\n",
    "df_basis2['LVL'][mask] = 8\n",
    "\n",
    "mask = df_basis2['PROFILE'] == 0\n",
    "df_basis2['STILL_MISSING'][mask] = 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exports final output to CSV. Then to give formatting for allocation team to use.\n",
    "#df_basis2.to_csv(\"df_basis_output.csv\")\n",
    "#df_basis2.to_excel(\"df_basis_output_xl.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
